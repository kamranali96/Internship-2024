{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "634c3360-24f0-46ed-9913-feb1a82daf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed22a947-e91c-4bc5-a5c5-cab4c26ccefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6705710.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 49870602.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 6055305.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4496230.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "dataset=torchvision.datasets.MNIST(root='./data',download=True,train=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce001e9b-bf04-46be-826a-2c0adfc76dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 60000\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset size\",len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad4695d-7ff7-46c3-9fce-1ff548a5279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 36000\n",
      "valid size 12000\n",
      "test size 12000\n"
     ]
    }
   ],
   "source": [
    "totalsize=len(dataset)\n",
    "train_size=int(0.6*totalsize)\n",
    "valid_size=int(0.2*totalsize)\n",
    "test_size=int(0.2*totalsize)\n",
    "print(\"train size\",train_size)\n",
    "print(\"valid size\",valid_size)\n",
    "print(\"test size\",test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e090b1-d0d9-4a09-8d39-81f4653940f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,valid_dataset,test_dataset=random_split(dataset,[train_size,valid_size,test_size] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5851086-7e6f-4d49-a839-e32d125336cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validloader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8792c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(MobileNet, self).__init__()  # Corrected here\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = MobileNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced4c2aa-817e-40d3-8de8-29d42509e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e28f269e-1a5d-4629-b185-934841e18295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2072, Train Accuracy: 93.39%\n",
      "Epoch 2, Train Loss: 0.0751, Train Accuracy: 97.67%\n",
      "Epoch 3, Train Loss: 0.0670, Train Accuracy: 97.98%\n",
      "Epoch 4, Train Loss: 0.0591, Train Accuracy: 98.22%\n",
      "Epoch 5, Train Loss: 0.0544, Train Accuracy: 98.38%\n",
      "Epoch 6, Train Loss: 0.0623, Train Accuracy: 98.17%\n",
      "Epoch 7, Train Loss: 0.0535, Train Accuracy: 98.51%\n",
      "Epoch 8, Train Loss: 0.0578, Train Accuracy: 98.38%\n",
      "Epoch 9, Train Loss: 0.0485, Train Accuracy: 98.62%\n",
      "Epoch 10, Train Loss: 0.0526, Train Accuracy: 98.56%\n"
     ]
    }
   ],
   "source": [
    "# training the model \n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "       \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f43144-757c-45bc-89d4-74fb1f8e62db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Loss: 0.0907, Validation Accuracy: 98.20%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Validation \n",
    "model.eval()  \n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data in validloader:  \n",
    "        images, labels = data[0].to(device), data[1].to(device) \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "\n",
    "        running_loss += loss.item()  \n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        total += labels.size(0)  \n",
    "        correct += (predicted == labels).sum().item() \n",
    "\n",
    "\n",
    "val_loss = running_loss / len(validloader)\n",
    "val_accuracy = 100 * correct / total\n",
    "\n",
    "\n",
    "print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6098f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1017, Test Accuracy: 97.94%\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model.eval()  \n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data in testloader:  \n",
    "        images, labels = data[0].to(device), data[1].to(device) \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels) \n",
    "\n",
    "        running_loss += loss.item()  \n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        total += labels.size(0) \n",
    "        correct += (predicted == labels).sum().item()  \n",
    "\n",
    "\n",
    "test_loss = running_loss / len(testloader)\n",
    "test_accuracy = 100 * correct / total\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
